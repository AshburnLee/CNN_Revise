{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['batches.meta', 'data_batch_1', 'data_batch_2', 'data_batch_3', 'data_batch_4', 'data_batch_5', 'readme.html', 'test_batch']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import CifarData\n",
    "\n",
    "CIFAR_DIR = \"./../cifar-10-batches-py\"\n",
    "print(os.listdir(CIFAR_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, \\nwith 6000 images per class. There are 50000 training images and 10000 test images. \\n\\n## data -- a 10000x3072(32*32*3) numpy array of uint8s. \\nEach row of the array stores a 32x32 colour image. \\nThe first 1024 entries contain the red channel values, \\nthe next 1024 the green, and the final 1024 the blue. \\nThe image is stored in row-major order, so that the first 32 entries of the array \\nare the red channel values of the first row of the image.\\n\\n## labels -- a list of 10000 numbers in the range 0-9. \\nThe number at index i indicates the label of the ith image in the array data.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, \n",
    "with 6000 images per class. There are 50000 training images and 10000 test images. \n",
    "\n",
    "## data -- a 10000x3072(32*32*3) numpy array of uint8s. \n",
    "Each row of the array stores a 32x32 colour image. \n",
    "The first 1024 entries contain the red channel values, \n",
    "the next 1024 the green, and the final 1024 the blue. \n",
    "The image is stored in row-major order, so that the first 32 entries of the array \n",
    "are the red channel values of the first row of the image.\n",
    "\n",
    "## labels -- a list of 10000 numbers in the range 0-9. \n",
    "The number at index i indicates the label of the ith image in the array data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072)\n",
      "(50000,)\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[[ 0.92941176  0.94509804  0.95294118 ...,  0.22352941  0.15294118\n",
      "   0.1372549 ]\n",
      " [ 0.4745098   0.42745098  0.46666667 ...,  0.00392157  0.01176471\n",
      "   0.01960784]\n",
      " [ 0.73333333  0.71764706  0.7254902  ..., -0.38823529 -0.38823529\n",
      "  -0.35686275]\n",
      " ..., \n",
      " [ 0.1372549   0.09019608  0.09803922 ...,  0.05882353  0.03529412\n",
      "   0.01176471]\n",
      " [ 0.21568627  0.24705882  0.28627451 ...,  0.03529412  0.01960784\n",
      "   0.01176471]\n",
      " [-0.40392157 -0.42745098 -0.54509804 ..., -0.41960784 -0.28627451\n",
      "  -0.33333333]]\n",
      "[8 0 9 3 1 4 0 8 6 6]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "testing \n",
    "\"\"\"\n",
    "train_filenames = [os.path.join(CIFAR_DIR, 'data_batch_%d' % i) for i in range(1, 6)]\n",
    "test_filenames = [os.path.join(CIFAR_DIR, 'test_batch')]\n",
    "\n",
    "train_data = CifarData.CifarData(train_filenames, True)\n",
    "test_data = CifarData.CifarData(test_filenames, False)\n",
    "\n",
    "tst_batch_data, tst_batch_labels = train_data.next_batch(10)\n",
    "print(tst_batch_data)\n",
    "print(tst_batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "create compute graph\n",
    "single layer net work with 10 neurons\n",
    "\"\"\"\n",
    "x = tf.placeholder(tf.float32, [None, 3072])\n",
    "# [None], eg: [0,5,6,3]\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "\n",
    "# 10-classification need 10 outputs\n",
    "# (3072, 10)\n",
    "w = tf.get_variable('w', [x.get_shape()[-1], 10],\n",
    "                   initializer=tf.random_normal_initializer(0, 1))\n",
    "# (10, )\n",
    "b = tf.get_variable('b', [10],\n",
    "                   initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "# [None, 3072] * [3072, 10] = [None, 10]\n",
    "y_ = tf.matmul(x, w) + b\n",
    "\n",
    "# mean square loss\n",
    "\"\"\"\n",
    "# course: 1 + e^x\n",
    "# api: e^x / sum(e^x)\n",
    "# [[0.01, 0.9, ..., 0.03], [], ...] # 10000*[], \n",
    "p_y = tf.nn.softmax(y_)\n",
    "# 5 -> [0,0,0,0,0,1,0,0,0,0]\n",
    "y_one_hot = tf.one_hot(y, 10, dtype=tf.float32)\n",
    "loss = tf.reduce_mean(tf.square(y_one_hot - p_y))\n",
    "\"\"\"\n",
    "\n",
    "# cross entropy loss\n",
    "loss = tf.losses.sparse_softmax_cross_entropy(labels=y, logits=y_)\n",
    "# what does it do:\n",
    "# y_ -> sofmax\n",
    "# y -> one_hot\n",
    "# loss = ylogy_\n",
    "\n",
    "\n",
    "\n",
    "# indices\n",
    "predict = tf.argmax(y_, 1)  # dim 0 or dim 1   \n",
    "# [1,0,1,1,1,0,0,0]\n",
    "correct_prediction = tf.equal(predict, y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float64))\n",
    "\n",
    "with tf.name_scope('train_op'):\n",
    "    train_op = tf.train.AdamOptimizer(1e-3).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step: 500, loss: 24.65310, acc: 0.10000\n",
      "[Train] Step: 1000, loss: 15.06285, acc: 0.20000\n",
      "[Train] Step: 1500, loss: 9.73833, acc: 0.15000\n",
      "[Train] Step: 2000, loss: 15.42166, acc: 0.25000\n",
      "[Train] Step: 2500, loss: 7.89101, acc: 0.30000\n",
      "[Train] Step: 3000, loss: 7.93487, acc: 0.30000\n",
      "[Train] Step: 3500, loss: 11.79579, acc: 0.15000\n",
      "[Train] Step: 4000, loss: 8.43897, acc: 0.25000\n",
      "[Train] Step: 4500, loss: 5.28395, acc: 0.25000\n",
      "[Train] Step: 5000, loss: 7.86700, acc: 0.25000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 5000, acc: 0.24400\n",
      "[Train] Step: 5500, loss: 11.23963, acc: 0.30000\n",
      "[Train] Step: 6000, loss: 6.48047, acc: 0.40000\n",
      "[Train] Step: 6500, loss: 3.88700, acc: 0.35000\n",
      "[Train] Step: 7000, loss: 5.99141, acc: 0.30000\n",
      "[Train] Step: 7500, loss: 7.26124, acc: 0.20000\n",
      "[Train] Step: 8000, loss: 4.84996, acc: 0.25000\n",
      "[Train] Step: 8500, loss: 7.09732, acc: 0.35000\n",
      "[Train] Step: 9000, loss: 6.87352, acc: 0.20000\n",
      "[Train] Step: 9500, loss: 6.81222, acc: 0.35000\n",
      "[Train] Step: 10000, loss: 4.85149, acc: 0.25000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 10000, acc: 0.25850\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "batch_size = 20\n",
    "train_steps = 10000\n",
    "test_steps = 100\n",
    "\n",
    "# run 100k: 30.95%\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(train_steps):\n",
    "        batch_data, batch_labels = train_data.next_batch(batch_size)\n",
    "        loss_val, acc_val, _ = sess.run(\n",
    "                                        [loss, accuracy, train_op],\n",
    "                                        feed_dict={\n",
    "                                            x: batch_data,\n",
    "                                            y: batch_labels}\n",
    "                                        )\n",
    "        if (i+1) % 500 == 0:\n",
    "            print('[Train] Step: %d, loss: %4.5f, acc: %4.5f' \n",
    "                  % (i+1, loss_val, acc_val))\n",
    "        if (i+1) % 5000 == 0:\n",
    "            test_data = CifarData.CifarData(test_filenames, False)\n",
    "            all_test_acc_val = []\n",
    "            for j in range(test_steps):\n",
    "                test_batch_data, test_batch_labels = test_data.next_batch(batch_size)\n",
    "                test_acc_val = sess.run(\n",
    "                                        [accuracy],\n",
    "                                        feed_dict = {\n",
    "                                            x: test_batch_data, \n",
    "                                            y: test_batch_labels}\n",
    "                                        )\n",
    "                all_test_acc_val.append(test_acc_val)\n",
    "            test_acc = np.mean(all_test_acc_val)\n",
    "            print('[Test ] Step: %d, acc: %4.5f' % (i+1, test_acc))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
